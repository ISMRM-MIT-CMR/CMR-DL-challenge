{
 "cells": [
  {
   "source": [
    "<a href=\"https://colab.research.google.com/github/khammernik/tk_kh_projects/blob/master/educational/02_ismrm_cardiac_educational/tutorial_denoising_complex.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **Example 02: Denoising on complex-valued data with complex-valued operations**\n",
    "We first define the data pipelines to feed the data into training, validation and test set. The MNIST database is used for showcasing. Since MNIST are real-valued images, a phase is simulated and added to the images to generate a complex-valued input. A white Gaussian noise is simulated retrospectively and added to the data. The task of the network is to denoise the images with complex-valued operations. You can compare the different processing to the pure real-valued case (Example 01) and to handling the complex-valued data in 2 real-valued channels (Example 03).\n",
    "\n",
    "To enable GPU support in Google Colab, please go to `Edit -> Notebook settings` and select `GPU` as hardware accelerator."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# inspect the available GPU hardware\n",
    "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
    "!nvidia-smi"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONLY execute if called from Google Colab or if files are not yet present\n",
    "! wget https://www.dropbox.com/sh/sag71gy9byxplc3/AACmXeOhXvW8HuLujPaqUPP_a?dl=1 -O dlmri_tutorial.zip\n",
    "! unzip dlmri_tutorial.zip -d dlmri_tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Database pipeline\n",
    "Here starts the main part of the script. First define the data pipelines (in the form of generator functions) for training, validation and test set. Retrospective noise simulation is performed inside the generator functions."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime\n",
    "import dlmri_tutorial\n",
    "\n",
    "from dlmri_tutorial.data import ComplexDataGeneratorMNIST  # complex-valued data generator\n",
    "\n",
    "# initialize some parameters\n",
    "noise_level = 0.5  # simulated additive white Gaussian noise level\n",
    "\n",
    "# Data Generators (Data pipeline) for complex-valued data\n",
    "# training set\n",
    "training_generator = ComplexDataGeneratorMNIST(batch_size=32, \n",
    "                                    noise_level=noise_level,\n",
    "                                    shuffle=True,\n",
    "                                    mode='train')\n",
    "\n",
    "# validation set\n",
    "validation_generator = ComplexDataGeneratorMNIST(batch_size=32, \n",
    "                                    noise_level=noise_level,\n",
    "                                    shuffle=False,\n",
    "                                    mode='val')\n",
    "\n",
    "# test set\n",
    "# ideally testing should be performed on real noisy cases and not simulated ones\n",
    "test_generator = ComplexDataGeneratorMNIST(batch_size=1,   \n",
    "                                    shuffle=False,\n",
    "                                    mode='test')\n",
    "\n",
    "print('Training batches to process:', len(training_generator))\n",
    "print('Validation batches to process:', len(validation_generator))\n",
    "print('Test samples to process:', len(test_generator))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model\n",
    "Define the CNN model with its corresponding inputs and outputs.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3-layer convolutional neural network (CNN)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Model\n",
    "# Let's start with a 3-layer CNN\n",
    "input = tf.keras.Input(shape=(28, 28, 1), dtype='complex64')  # define input layer and its shape, complex-valued tensors\n",
    "activation = 'cReLU'  # select activation function: complex-valued ReLU\n",
    "# convolutional layer 1: Complex-valued convolution\n",
    "conv_out1 = dlmri_tutorial.keras.layers.ComplexConv2D(filters=4,                # output channels, N_fout\n",
    "                                kernel_size=(3,3),              # kernel size along x and y\n",
    "                                strides=(1,1),                  # stride performed along x and y\n",
    "                                padding='SAME',                 # padding of input to adjust output size\n",
    "                                use_bias=True,                  # learn bias values for conv layer\n",
    "                                activation=activation)(input)   # apply activation function after conv operation\n",
    "# convolutional layer 2: Complex-valued convolution\n",
    "conv_out2 = dlmri_tutorial.keras.layers.ComplexConv2D(filters=4,\n",
    "                                kernel_size=(3,3),\n",
    "                                strides=(1,1),\n",
    "                                padding='SAME',\n",
    "                                use_bias=True,\n",
    "                                activation=activation)(conv_out1)\n",
    "# convolutional layer 3: Complex-valued convolution\n",
    "output    = dlmri_tutorial.keras.layers.ComplexConv2D(filters=1,\n",
    "                                kernel_size=(3,3),\n",
    "                                strides=(1,1),\n",
    "                                padding='SAME',\n",
    "                                use_bias=True,\n",
    "                                activation=activation)(conv_out2)\n",
    "\n",
    "# instantiate a keras functional model: combine layers into a model with specified inputs and outputs\n",
    "model = tf.keras.Model(input, output, name='3layerCNNComplex')\n",
    "\n",
    "# print model overview\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3-layer residual convolutional neural network (CNN)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Model\n",
    "# Let's start with a residual 3-layer CNN\n",
    "input = tf.keras.Input(shape=(28, 28, 1), dtype='complex64')  # define input layer and its shape, complex-valued tensors\n",
    "activation = 'cReLU'  # select activation function: complex-valued ReLU\n",
    "# convolutional layer 1: Complex-valued convolution\n",
    "conv_out1 = dlmri_tutorial.keras.layers.ComplexConv2D(filters=4,                # output channels, N_fout\n",
    "                                kernel_size=(3,3),              # kernel size along x and y\n",
    "                                strides=(1,1),                  # stride performed along x and y\n",
    "                                padding='SAME',                 # padding of input to adjust output size\n",
    "                                use_bias=True,                  # learn bias values for conv layer\n",
    "                                activation=activation)(input)   # apply activation function after conv operation\n",
    "# convolutional layer 2: Complex-valued convolution\n",
    "conv_out2 = dlmri_tutorial.keras.layers.ComplexConv2D(filters=4,\n",
    "                                kernel_size=(3,3),\n",
    "                                strides=(1,1),\n",
    "                                padding='SAME',\n",
    "                                use_bias=True,\n",
    "                                activation=activation)(conv_out1)\n",
    "# convolutional layer 3: Complex-valued convolution\n",
    "residual    = dlmri_tutorial.keras.layers.ComplexConv2D(filters=1,\n",
    "                                kernel_size=(3,3),\n",
    "                                strides=(1,1),\n",
    "                                padding='SAME',\n",
    "                                use_bias=True,\n",
    "                                activation=activation)(conv_out2)\n",
    "# residual connection\n",
    "output = tf.keras.layers.Add()([input, residual])\n",
    "\n",
    "# instantiate a keras functional model: combine layers into a model with specified inputs and outputs\n",
    "model = tf.keras.Model(input, output, name='Residual3layerCNNComplex')\n",
    "\n",
    "# print model overview\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Build model\n",
    "Compile the model, assign an optimizer, loss function and validation metrics. Prepare some keras callbacks to monitor training progress."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),      # used optimizer with chosen learning rate\n",
    "              loss='mse',                                                   # loss function (note: TF can perform real-valued mse loss on complex-valued input) \n",
    "              metrics=['mse', 'mae'])                                       # evaluation metrics (for training and validation set)\n",
    "\n",
    "# define callbacks to monitor model\n",
    "keras_callbacks = dlmri_tutorial.get_callbacks(validation_generator, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Tensorboard\n",
    "Start the Tensorboard [optional] to monitor training progress and display validation outputs."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start Tensorboard\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=logs"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training\n",
    "Train the configured and compiled model. Monitor training progress with validation set."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model with training set and evaluate its performance with the validation set\n",
    "model.fit(training_generator,                       # training set\n",
    "          validation_data=validation_generator,     # validation set\n",
    "          epochs=3,                                 # number of epochs to train the model\n",
    "          callbacks=keras_callbacks)                # callbacks to monitor or control training"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Testing\n",
    "Test the trained model to predict a denoised output and to display performance (metrics) on test set."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# predict with trained model\n",
    "predicted_output = model.predict(test_generator)\n",
    "\n",
    "# evaluate trained model\n",
    "loss_metric_test = model.evaluate(test_generator)\n",
    "\n",
    "# display the predicted output\n",
    "import matplotlib.pyplot as plt\n",
    "icase = 0  # display the first example\n",
    "plt.imshow(np.squeeze(np.abs(predicted_output)[icase,]), cmap=plt.gray())\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}