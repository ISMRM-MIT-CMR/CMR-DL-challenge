{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "challenge_plug_and_play.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPTp1txUtJCkz7byzw2r1Ou",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ISMRM-MIT-CMR/CMR-DL-challenge/blob/master/challenge_plug_and_play.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tNtPqpBT9dSE"
      },
      "source": [
        "# Deep Plug-and-Play Priors\n",
        "Deep plug-and-play priors exploit the advantages of learning an advanced denoising scheme offline and plugging it into any optimization scheme to solve inverse problems, such as Magnetic Resonance Image Reconstruction.\n",
        "\n",
        "## The CHALLENGE\n",
        "The goal of this challenge is to find a way to reconstruct complex-valued MR images by using available denoisers. The plug-and-play prior challenge consists of two tasks:\n",
        "1. Deploying a denoising model. If you plan to use available denoisers trained on real-valued images, you have to think about a way to apply them to the complex-valued images.\n",
        "2. Definition of an optimization scheme. Inspiration can be found in the Suggested Reading section.\n",
        "\n",
        "The code parts that have to be changed are marked with TODO.\n",
        "\n",
        "The dataset `subject1.h5`, containing fully sampled k-space, can be used for quantitative and qualitative evaluation in the deployment phase. The results have to be generated for `subject2.h5`, which contains the undersampled k-space. The challenge will be evaluated quantitatively using the normalized root mean squared error (NRMSE), and based on the creativity and complexity to generate the solution.\n",
        "\n",
        "We are looking forward to your creative submissions! Happy coding!\n",
        "\n",
        "## The data\n",
        "We provide two cardiac CINE datasets, with a single cardiac frame:\n",
        "- `subject1.h5` contains the fully sampled k-space `kspace`, coil sensitivity maps `cmap`, and sampling masks at acceleration factors R=4 (`mask_R4`) and R=6 (`mask_R6`).\n",
        "- `subject2.h5` is the _challenge_ subject and contains the undersampled k-space `kspace`, coil sensitivity maps `cmap` and the sampling mask `mask_R4`.\n",
        "\n",
        "To process these datasets, we provide the basic framework for MRI reconstruction.\n",
        "\n",
        "## Suggested readings\n",
        "- S. V. Venkatakrishnan, C. A. Bouman and B. Wohlberg. [Plug-and-Play priors for model based reconstruction](https://ieeexplore.ieee.org/document/6737048). In: IEEE Global Conference on Signal and Information Processing, 2013, pp. 945-948, 2013.\n",
        "\n",
        "- Meinhardt et al. [Learning Proximal Operators:\n",
        "Using Denoising Networks for Regularizing Inverse Imaging Problems](https://openaccess.thecvf.com/content_ICCV_2017/papers/Meinhardt_Learning_Proximal_Operators_ICCV_2017_paper.pdf). In: IEEE International Conference on Computer Vision (ICCV), pp. 1799-1808, 2017.\n",
        "\n",
        "- Zhang et al. [Plug-and-Play Image Restoration with Deep Denoiser Prior](https://openaccess.thecvf.com/content_cvpr_2017/papers/Zhang_Learning_Deep_CNN_CVPR_2017_paper.pdf). In: IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 2808-2817, 2017.\n",
        "\n",
        "- Yazdanpanah et al. [Deep Plug-and-Play Prior for Parallel MRI Reconstruction](https://openaccess.thecvf.com/content_ICCVW_2019/papers/LCI/Yazdanpanah_Deep_Plug-and-Play_Prior_for_Parallel_MRI_Reconstruction_ICCVW_2019_paper.pdf). In: Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV) Workshops, 2019."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WoZ8hJEJ6K31"
      },
      "source": [
        "## Sample Denoising Network\n",
        "The following code downloads the DnCNN denoising network that can be used in the Plug-and-Play prior challenge. Another code snippet is added to test the denoising model on image denoising.\n",
        "\n",
        "Zhang et al. [Beyond a Gaussian Denoiser: Residual Learning of Deep CNN for Image Denoising](https://ieeexplore.ieee.org/document/7839189). IEEE Transactions on Image Processing, vol. 26, no. 7, pp. 3142-3155, 2017."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EYWgB3Go6H2z"
      },
      "source": [
        "import os\n",
        "from tensorflow.keras.models import model_from_json\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "if not os.path.exists('./trained_models'):\n",
        "    os.makedirs('./trained_models')\n",
        "\n",
        "if not os.path.exists('./trained_models/dncnn.json'):\n",
        "    os.system('wget https://raw.githubusercontent.com/cszn/DnCNN/master/TrainingCodes/dncnn_keras/models/DnCNN_sigma25/model.json -O ./trained_models/dncnn.json')\n",
        "\n",
        "if not os.path.exists('./trained_models/dncnn.h5'):\n",
        "    os.system('wget https://raw.githubusercontent.com/cszn/DnCNN/master/TrainingCodes/dncnn_keras/models/DnCNN_sigma25/model.h5 -O ./trained_models/dncnn.h5')\n",
        "    \n",
        "# Download Set12\n",
        "for i in range(1, 12):\n",
        "    if not os.path.exists(f'./data/denoising/Set12/{i:02d}.png'):\n",
        "        os.system(f'wget https://raw.githubusercontent.com/cszn/DnCNN/master/TrainingCodes/dncnn_keras/data/Test/Set12/{i:02d}.png -P ./data/denoising/Set12/')\n",
        "\n",
        "json_file = open('trained_models/dncnn.json', 'r')\n",
        "loaded_model_json = json_file.read()\n",
        "json_file.close()\n",
        "model = model_from_json(loaded_model_json)\n",
        "# load weights into new model\n",
        "model.load_weights('./trained_models/dncnn.h5')\n",
        "\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ee06lmM7dXC"
      },
      "source": [
        "import imageio\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "sigma = 25\n",
        "\n",
        "def to_tf(x):\n",
        "    return x[None,...,None]\n",
        "\n",
        "def from_tf(x):\n",
        "    return np.squeeze(x)\n",
        "\n",
        "target = imageio.imread('./data/denoising/Set12/01.png').astype(np.float32)/255.0\n",
        "noisy = target + np.random.normal(0, sigma/255.0, target.shape)\n",
        "prediction = from_tf(model.predict(to_tf(noisy)))\n",
        "\n",
        "plt.figure(figsize=(15,5))\n",
        "plt.subplot(1,3,1)\n",
        "plt.imshow(target, cmap='gray')\n",
        "plt.title('Target')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.subplot(1,3,2)\n",
        "plt.imshow(noisy, cmap='gray')\n",
        "plt.title(f'Noisy $\\sigma$={sigma}')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.subplot(1,3,3)\n",
        "plt.imshow(prediction, cmap='gray')\n",
        "plt.title(f'DnCNN')\n",
        "plt.axis('off')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ReZHr2LfCY3i"
      },
      "source": [
        "## Data Loading\n",
        "\n",
        "In the following, we load the data for `subject1.h5`. The challenge will be evaluated on `subject2.h5`!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dwAI6WhLNDAP"
      },
      "source": [
        "if not os.path.exists('./data/subject1.h5'):\n",
        "    os.system('wget https://github.com/ISMRM-MIT-CMR/CMR-DL-challenge/raw/master/data/subject1.h5 -O ./data/subject1.h5')\n",
        "\n",
        "if not os.path.exists('./data/subject2.h5'):\n",
        "    os.system('wget https://github.com/ISMRM-MIT-CMR/CMR-DL-challenge/raw/master/data/subject2.h5 -O ./data/subject2.h5')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xi-_24tsE2sq"
      },
      "source": [
        "import h5py\n",
        "subId = 1 # subject ID. For the challenge task, please set to 2.\n",
        "\n",
        "with h5py.File(f'./data/subject{subId}.h5', 'r') as f:\n",
        "  kspace = f['kspace'][()]\n",
        "  csm = f['csm'][()]\n",
        "  mask = f['mask_R4'][()]\n",
        "\n",
        "print('Dimensions: ')\n",
        "print('kspace: ', kspace.shape)\n",
        "print('csm: ', csm.shape)\n",
        "print('mask: ', mask.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZiQ6--zzHmm7"
      },
      "source": [
        "## Data Visualization and Evaluation\n",
        "\n",
        "We provide basic evaluation and visualization tools here."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OgUum5xTGmrI"
      },
      "source": [
        "def center_crop(data, shape):\n",
        "    \"\"\"\n",
        "    [source] https://github.com/facebookresearch/fastMRI/blob/master/data/transforms.py\n",
        "    [source] https://github.com/khammernik/medutils/blob/master/medutils/visualization.py\n",
        "    Apply a center crop to the input real image or batch of real images.\n",
        "    Args:\n",
        "        data (numpy.array): The input tensor to be center cropped. It should have at\n",
        "            least 2 dimensions and the cropping is applied along the last two dimensions.\n",
        "        shape (int, int): The output shape. The shape should be smaller than the\n",
        "            corresponding dimensions of data.\n",
        "    Returns:\n",
        "        numpy.array: The center cropped image\n",
        "    \"\"\"\n",
        "    assert 0 < shape[0] <= data.shape[-2]\n",
        "    assert 0 < shape[1] <= data.shape[-1]\n",
        "    w_from = (data.shape[-2] - shape[0]) // 2\n",
        "    h_from = (data.shape[-1] - shape[1]) // 2\n",
        "    w_to = w_from + shape[0]\n",
        "    h_to = h_from + shape[1]\n",
        "    return data[..., w_from:w_to, h_from:h_to]\n",
        "\n",
        "def process4display(x):\n",
        "    \"\"\"\n",
        "        Helper function to compute the magnitude and crop the image to the central part, which will\n",
        "        be evaluated.\n",
        "    \"\"\"\n",
        "    return center_crop(np.abs(x), (100, 100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0jPhZfrHlgN"
      },
      "source": [
        "def nrmse(x, x_ref):\n",
        "    \"\"\"\n",
        "    Compute the Normalized Root Mean Squared Error\n",
        "    Args:\n",
        "        x (np.array): predicted image\n",
        "        x_ref (np.array): target image\n",
        "    Return:\n",
        "        float: Computed metric\n",
        "    \"\"\"\n",
        "    x = center_crop(x, (100, 100))\n",
        "    x_ref = center_crop(x_ref, (100, 100))\n",
        "    return np.sqrt(np.sum((np.abs(x_ref) - np.abs(x))**2) / np.sum(np.abs(x_ref)**2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQ3M2PbKCvXi"
      },
      "source": [
        "## MRI Reconstruction\n",
        "\n",
        "In the following, we defined the forward and adjoint operators for Cartesian 2D MRI reconstruction."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CUCuL-wN6YE7"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Define Cartesian Forward Operator\n",
        "def forwardOp(x, csm, mask):\n",
        "    def fft2c(x, axes=(-2,-1)):\n",
        "      return np.fft.fftshift(np.fft.fft2(np.fft.ifftshift(x, axes=axes), axes=axes, norm='ortho'), axes=axes)\n",
        "    return fft2c(x * csm, axes=(1,2)) * mask\n",
        "A = lambda x: forwardOp(x, csm, mask)\n",
        "\n",
        "# Define Cartesian Adjoint Operator\n",
        "def adjointOp(y, csm, mask):\n",
        "    def ifft2c(y, axes=(-2,-1)):\n",
        "      return np.fft.fftshift(np.fft.ifft2(np.fft.ifftshift(y, axes=axes), axes=axes, norm='ortho'), axes=axes)\n",
        "    return np.sum(ifft2c(y * mask, (1,2)) * np.conj(csm), 0)\n",
        "AH = lambda y: adjointOp(y, csm, mask)\n",
        "\n",
        "# Test adjointness\n",
        "p = np.random.randn(*kspace.shape)\n",
        "u = np.random.randn(*AH(kspace).shape)\n",
        "lhs = np.sum(A(u) * np.conj(p))\n",
        "rhs = np.sum(u * np.conj(AH(p)))\n",
        "print(lhs, rhs)\n",
        "\n",
        "# Store in operator class to be used in the Conjugate Gradient (CG) Optimizer\n",
        "class MRIOperator():\n",
        "    def forward(self, x):\n",
        "        return A(x)\n",
        "    def adjoint(self, x):\n",
        "        return AH(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xkppam84QKn2"
      },
      "source": [
        "Now, we can compute the undersampled image (zero filling), and the target image.\n",
        "Please note that the target does not exist for `subject2.h5`!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oo6GjhXyFfJs"
      },
      "source": [
        "# Compute zero filling\n",
        "zero_filling = AH(kspace * mask)\n",
        "\n",
        "# Normalize data\n",
        "norm = np.max(np.abs(zero_filling))\n",
        "kspace /= norm\n",
        "\n",
        "# Compute target\n",
        "if subId == 1:\n",
        "  target = adjointOp(kspace, csm, np.ones_like(mask))\n",
        "else:\n",
        "  target = np.zeros_like(zero_filling)\n",
        "\n",
        "print(nrmse(zero_filling, target))\n",
        "plt.figure(figsize=(15,5))\n",
        "plt.subplot(1,3,1)\n",
        "plt.imshow(process4display(zero_filling), cmap='gray')\n",
        "plt.title('zero filling')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.subplot(1,3,2)\n",
        "plt.imshow(np.ones_like(np.abs(zero_filling))*mask, cmap='gray')\n",
        "plt.title('sampling mask')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.subplot(1,3,3)\n",
        "plt.imshow(process4display(target), cmap='gray')\n",
        "plt.title('target')\n",
        "plt.axis('off')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7oHr4MnYHMpQ"
      },
      "source": [
        "### Conjugate Gradient Optimization\n",
        "\n",
        "Pruessmann, K. P.; Weiger, M.; Boernert, P. and Boesiger, P.\n",
        "        [Advances in sensitivity encoding with arbitrary k-space trajectories.](https://onlinelibrary.wiley.com/doi/full/10.1002/mrm.1241?sid=nlm%3Apubmed)\n",
        "        Magn Reson Med 46: 638-651 (2001)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tCRztoeGHSJl"
      },
      "source": [
        "# CG SENSE Reconstruction\n",
        "class CgSenseReconstruction(object):\n",
        "    \"\"\" CG Reconstruction using the algorithm in [1].\n",
        "    [1] Pruessmann, K. P.; Weiger, M.; Boernert, P. and Boesiger, P.\n",
        "        Advances in sensitivity encoding with arbitrary k-space trajectories.\n",
        "        Magn Reson Med 46: 638-651 (2001)\n",
        "    \"\"\"\n",
        "    def __init__(self, op, alpha=0, tol=1e-6, max_iter=50):\n",
        "        \"\"\" Initialization\n",
        "        :param op: operator class containing a forward and adjoint method\n",
        "        :param alpha: Tikohonov regularization parameter\n",
        "        :param tol: relative tolerance\n",
        "        :param max_iter: maximum number of iterations\n",
        "        \"\"\"\n",
        "        self._alpha = alpha\n",
        "        self._tol = tol\n",
        "        self._max_iter = max_iter\n",
        "        self.op = op\n",
        "\n",
        "    @property\n",
        "    def alpha(self):\n",
        "        return self._alpha\n",
        "\n",
        "    @alpha.setter\n",
        "    def alpha(self, value):\n",
        "        self._alpha = value\n",
        "\n",
        "    @property\n",
        "    def tol(self):\n",
        "        return self._tol\n",
        "\n",
        "    @tol.setter\n",
        "    def tol(self, value):\n",
        "        self._tol = value\n",
        "\n",
        "    @property\n",
        "    def max_iter(self):\n",
        "        return self._max_iter\n",
        "\n",
        "    @max_iter.setter\n",
        "    def max_iter(self, value):\n",
        "        self._max_iter = value\n",
        "        \n",
        "    def complexDot(self, u, v):\n",
        "        \"\"\" Compute complex dot product\n",
        "        :param u: np.array\n",
        "        :param v: np.array\n",
        "        :return: complex dot product of u and v\n",
        "        \"\"\"\n",
        "        return np.dot(np.conjugate(u.flatten()) , v.flatten())\n",
        "    \n",
        "    def normSquared(self, u):\n",
        "        \"\"\" Compute squared norm\n",
        "        :param u: np.array\n",
        "        :return: squared norm of u\n",
        "        \"\"\"\n",
        "        return np.real(np.dot(np.conjugate(u.flatten()) , u.flatten()))\n",
        "\n",
        "    def __systemMatrix__(self, x):\n",
        "        \"\"\" Compute result on system matrix A^H * A + alpha * I\n",
        "        :param x: np.array\n",
        "        :return: result for system matrix applied on x\n",
        "        \"\"\"\n",
        "        return self.op.adjoint(self.op.forward(x)) + self.alpha*x\n",
        "    \n",
        "    def solve(self, rhs, return_series=False, return_tol=False, verbose=False):\n",
        "        \"\"\" Compute solution\n",
        "        :param y: input data (np.array)\n",
        "        :param return_series: return the solutions for the individual iterations\n",
        "        :param return_tol: return tol for the individual iterations\n",
        "        :param verbose: boolean to turn on/off debug print\n",
        "        :return: return specified values\n",
        "        \"\"\"\n",
        "        x0 = np.zeros_like(rhs) + 1e-12 # a\n",
        "        x = np.zeros_like(rhs) # b_approx^(0)\n",
        "        r = rhs.copy()\n",
        "        p = r.copy()\n",
        "        rr = self.normSquared(r)\n",
        "        x0x0 = self.normSquared(x0) #a^Ha\n",
        "        it = 0\n",
        "        \n",
        "        recons = []\n",
        "        delta = [rr/x0x0]\n",
        "        \n",
        "        while rr/x0x0 > self.tol and it < self.max_iter:\n",
        "            q = self.__systemMatrix__(p) # q\n",
        "            tmp = rr / self.complexDot(p, q) # helper var\n",
        "            x += tmp*p.copy()\n",
        "            r -= tmp*q.copy()\n",
        "            p = r.copy() + (self.normSquared(r)/rr)*p.copy()\n",
        "            rr = self.normSquared(r)\n",
        "            if verbose:\n",
        "                print(it+1, rr/x0x0, self.tol)\n",
        "            it += 1\n",
        "            recons.append(x.copy())\n",
        "            delta.append(rr/x0x0)\n",
        "        \n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NSMHaw8eDb7s"
      },
      "source": [
        "def dataprox(x, alpha, y, x_ref=None, max_iter=20):\n",
        "    op = MRIOperator()\n",
        "    opt = CgSenseReconstruction(op, alpha, max_iter=max_iter)\n",
        "    rhs = op.adjoint(y) + alpha * x.copy()\n",
        "    x = opt.solve(rhs)\n",
        "    if x_ref is not None:\n",
        "        current_nrmse = nrmse(x, x_ref)\n",
        "        print(f\"NRMSE = {current_nrmse:.02f}\")\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0-Xvpc2HIJUA"
      },
      "source": [
        "Linear SENSE reconstruction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QdFtcCDGIGts"
      },
      "source": [
        "sense = dataprox(AH(kspace), 0, kspace, max_iter=10)\n",
        "if not subId == 2:\n",
        "  print(f'nrmse={nrmse(sense, target):.4g}')\n",
        "print(np.max(np.abs(sense)), np.max(np.abs(target)))\n",
        "plt.figure(figsize=(15,5))\n",
        "plt.subplot(1,3,1)\n",
        "plt.imshow(process4display(zero_filling), cmap='gray')\n",
        "plt.title('zero filling')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.subplot(1,3,2)\n",
        "plt.imshow(process4display(sense), cmap='gray')\n",
        "plt.title('SENSE reconstruction')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.subplot(1,3,3)\n",
        "plt.imshow(process4display(target), cmap='gray')\n",
        "plt.title('target')\n",
        "plt.axis('off')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9eKielWbJAmW"
      },
      "source": [
        "## CHALLENGE: Denoiser\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HtekC2UdJUKd"
      },
      "source": [
        "### Get Denoising model\n",
        "\n",
        "TODO: Adjust `getModel`\n",
        "\n",
        "We have provided a template here. You can adjust this template to use your favourite denoiser!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "twinBAk7JD-k"
      },
      "source": [
        "from tensorflow.keras.models import load_model, model_from_json\n",
        "\n",
        "def getModel():\n",
        "  #TODO: Adjust model and use your favourite denoiser!\n",
        "  \n",
        "  json_file = open('trained_models/dncnn.json', 'r')\n",
        "  loaded_model_json = json_file.read()\n",
        "  json_file.close()\n",
        "  model = model_from_json(loaded_model_json)\n",
        "  # load weights into new model\n",
        "  model.load_weights('./trained_models/dncnn.h5')\n",
        "  #<end todo>\n",
        "\n",
        "  print(model.summary())\n",
        "\n",
        "  return model\n",
        "\n",
        "model = getModel()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SpO3MK_mJnyv"
      },
      "source": [
        "### Define your denoiser\n",
        "\n",
        "TODO: Write `denoiser` function.\n",
        "\n",
        "TODO: Add helper functions if necessary.\n",
        "\n",
        "Here, you are applying the selected denoising model `model` to your data. How can it be applied to complex valued numbers? Think also about proper normalization and un-normalization! Denoising models are usually trained for a fixed dynamic range.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qsdvCDdFJnT6"
      },
      "source": [
        "def to_tf(x):\n",
        "    return x[None,...,None]\n",
        "\n",
        "def from_tf(x):\n",
        "    return np.squeeze(x)\n",
        "\n",
        "def denoiser(x, tau, x_ref=None):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "      x (np.array): input to the denoiser\n",
        "      tau (float): scalar applied before denoising as normalization, and after denoising as re-normalization.\n",
        "\n",
        "    Sample model call for real numbers: from_tf(model.predict(to_tf(x_re * tau))) / tau\n",
        "    \"\"\"\n",
        "    #TODO write your own denoiser here\n",
        "\n",
        "    #<end todo>\n",
        "\n",
        "    if x_ref is not None:\n",
        "        current_nrmse = nrmse(x, x_ref)\n",
        "        print(f\"NRMSE = {current_nrmse:.02f}\")\n",
        "\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VScvGZ_7LIbL"
      },
      "source": [
        "## CHALLENGE: Optimizer\n",
        "\n",
        "Here, you are going to write your optimizer! You can find inspirations in the provided literature.\n",
        "\n",
        "TODO: Write `optimizer` function. You can adapt the function handle if you need more parameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKXhi1snLWa6"
      },
      "source": [
        "def optimizer(y, alpha=1.0, tau=1.0, iter=10, cg_iter=10, x_ref=None):\n",
        "  \"\"\"\n",
        "  Args:\n",
        "    y (np.array): kspace\n",
        "    alpha (float): regularization parameter\n",
        "    tau (float): scaling parameter for denoiser to adapt input to trained noise level\n",
        "    iter (int): Total number of iteration for the optimization\n",
        "    cg_iter (int): Total number of iterations for the CG optimizer in the dataprox\n",
        "    x_ref (None, np.array): If target is provided, you receive some debug output (nrmse)\n",
        "  \"\"\"\n",
        "\n",
        "  #TODO choose your favourite optimizer! In the following, you find a template.\n",
        "\n",
        "  x = AH(y)\n",
        "\n",
        "  for k in range(iter):\n",
        "    # Prox (reg)\n",
        "    x = denoiser(x, tau)\n",
        "\n",
        "    # Prox (data)\n",
        "    x = dataprox(x, alpha, y, max_iter=cg_iter)\n",
        "\n",
        "    x_out = x\n",
        "\n",
        "    #<end todo>\n",
        "\n",
        "    if x_ref is not None:\n",
        "        current_nrmse = nrmse(x_out, x_ref)\n",
        "        print(f\"NRMSE {k} = {current_nrmse:.02f}\")\n",
        "  return x_out\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQKf_5yAMlLt"
      },
      "source": [
        "Now, let us run the optimization and check the final results! \n",
        "\n",
        "TODO: Adapt the parameters for your challenge solution!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCO1e2pPMkT6"
      },
      "source": [
        "# TODO: adapt the parameters here for the function call. When submitting, be sure that these\n",
        "# parameters are intended for `subject2.h5`.\n",
        "pnp = optimizer(kspace.copy(), alpha=1.0, tau=1.0, iter=10, cg_iter=10)\n",
        "# TODO: Please do not forget to fill out the Powerpoint template that we provided to present your\n",
        "# results.\n",
        "#<end todo>\n",
        "\n",
        "if not subId == 2:\n",
        "  print(f'nrmse={nrmse(pnp, target):.4g}')\n",
        "\n",
        "plt.figure(figsize=(15,5))\n",
        "plt.subplot(1,3,1)\n",
        "plt.imshow(process4display(zero_filling), cmap='gray')\n",
        "plt.title('zero filling')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.subplot(1,3,2)\n",
        "plt.imshow(process4display(pnp), cmap='gray')\n",
        "plt.title('PnP reconstruction')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.subplot(1,3,3)\n",
        "plt.imshow(process4display(target), cmap='gray')\n",
        "plt.title('target')\n",
        "plt.axis('off')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}